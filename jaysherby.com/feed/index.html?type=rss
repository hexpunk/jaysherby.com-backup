<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Jay's blog</title>
    <link>https://jaysherby.com/</link>
    <description>Hi! I'm Jay Sherby!

I'm an experienced software developer in Chicago....</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <item>
      <title>Target Optical Mailing List UI</title>
      <link>https://jaysherby.com/target-optical-mailing-list-ui/</link>
      <description>&lt;div&gt;&lt;p&gt;I recently received a spam email from Target Optical.  Subject line: "Happy Valentineâ€™s Day! ðŸ’•".  Thanks, Target.&lt;/p&gt;
&lt;p&gt;Naturally, I clicked on the unsubscribe link on the bottom of the email and I was met with...&lt;/p&gt;
&lt;p&gt;&lt;img alt="Oh, no! I forgot to censor my email address!! Whatever. Worst anyone could do would be re-adding me to Target Optical's mailing list." src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1678328483-0.png"&gt;&lt;/p&gt;
&lt;p&gt;I was aghast. I'd already had a rough day with software. This was the little push required to send me over the edge.  I laughed.  I cried.  I called my wife over to mercilessly mock this abject failure of usability.&lt;/p&gt;
&lt;p&gt;My best guess was to select the "yes" radio button and click the "submit" button.  I didn't have the patience to poke around. But what would "no" and "submit" mean?  Is that meaningfully different from "cancel"?&lt;/p&gt;
&lt;p&gt;It's not as bad as &lt;a href="https://dinosaurenby.medium.com/a-deep-dive-into-the-ux-of-the-nostromos-self-destruct-procedure-9eda80793fe8"&gt;the self-destruct interface for the Nostromo&lt;/a&gt;. If an alien creature was hunting me while I was trying to unsubscribe from this mailing list, I might not be as charitable.&lt;/p&gt;
&lt;p&gt;Luckily, my best guess was correct. And my piece of cheese for solving this UX puzzle?&lt;/p&gt;
&lt;p&gt;&lt;img alt="Unlike the previous image, this one has not been edited. Not one pixel." src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1678329253-0.png"&gt;&lt;/p&gt;
&lt;p&gt;Perfect. Ten out of ten.  No notes.  ðŸ¤¦&lt;/p&gt;
&lt;/div&gt;</description>
      <author>hidden (jaysherby)</author>
      <guid isPermaLink="false">https://jaysherby.com/target-optical-mailing-list-ui/</guid>
      <pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Terraform Cloud + CDKTF + Auth0</title>
      <link>https://jaysherby.com/terraform-cloud-cdktf-auth0/</link>
      <description>&lt;div&gt;&lt;p&gt;If you want my advice on how to manage Auth0 using CDKTF and Terraform Cloud, here it is: don't.&lt;/p&gt;
&lt;p&gt;But since you're still reading, I assume you find yourself in the regrettable situation of needing to support just such a setup.  Here are some little nuggets I've learned the hard way that don't seem to be documented elsewhere.&lt;/p&gt;
&lt;h2 id="rules-hooks-and-string-interpolation"&gt;Rules, Hooks, and String Interpolation&lt;/h2&gt;
&lt;p&gt;Rules and hooks are nifty features of Auth0 that allow you to run custom Javascript code on Auth0's servers in response to various events, like when a user signs up, logs in, etc.  From what I can tell, they both serve roughly the same purpose, although it seems like hooks are newer, and Auth0 would probably like to deprecate the rules feature very much.  They're both unpleasant to test, just like most kinds of code that run in other people's playgrounds.&lt;/p&gt;
&lt;p&gt;You may find yourself wanting to deploy the code for your rules and hooks using Terraform.  In the setup I inherited, the CDKTF scripts, written in Typescript, read source files for rules and hooks using &lt;code&gt;fs.readFileSync&lt;/code&gt;, and eventually insert their contents as a string into the JSON config that CDKTF synthesizes.&lt;/p&gt;
&lt;p&gt;Terraform Cloud sometimes reports errors during the planning step that say things like the following, while pointing the finger at the value for a rule's or hook's "script" key.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A reference to a resource type must be followed by at least one attribute access, specifying the resource name.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It'll highlight some seemingly random little bit of the long and mangled string that was once your Javascript source file.&lt;/p&gt;
&lt;p&gt;Every time I've ever seen this happen, the culprit is string interpolation in the Javascript file.&lt;/p&gt;
&lt;pre class="javascript"&gt;const domain = `app.${environment}.my-really-cool-app.com`;
&lt;/pre&gt;
&lt;p&gt;Terraform's parser sees &lt;code&gt;${&lt;/code&gt; in your string, which happens to be &lt;em&gt;its&lt;/em&gt; string interpolation syntax as well, and falls flat on its face trying to figure out what you're trying to accomplish.&lt;/p&gt;
&lt;p&gt;There are ways around this.  &lt;a href="https://developer.hashicorp.com/terraform/language/expressions/strings#escape-sequences-1"&gt;According to the docs&lt;/a&gt;, you can escape &lt;code&gt;${&lt;/code&gt; with &lt;code&gt;$${&lt;/code&gt;.&lt;sup class="footnote-ref" id="fnref-1"&gt;&lt;a href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;But are you really going to put &lt;code&gt;$${&lt;/code&gt; in your Javascript?  Absent of this context, &lt;code&gt;$${&lt;/code&gt; looks like a bug!  You could leave a comment explaining the extra &lt;code&gt;$&lt;/code&gt;.  But after the code is deployed, the comment will remain and the extra &lt;code&gt;$&lt;/code&gt; would disappear.  The comment wouldn't make sense if you looked at the code form inside the Auth0 management console.&lt;/p&gt;
&lt;p&gt;IMHO, doing this is asking for trouble.  Plus it feels gross.&lt;/p&gt;
&lt;p&gt;Worse yet, what if the name of the variable inside your interpolated string (&lt;code&gt;environment&lt;/code&gt; in the example above) &lt;em&gt;does&lt;/em&gt; mean something to Terraform and it replaces it with a value? The code would probably throw an error if the replaced value wasn't a variable in your script.  What if it was!?  In any case, the code deployed won't match the code in your repository.  Good luck chasing down that bug!&lt;/p&gt;
&lt;p&gt;The workaround I chose was to avoid template string interpolation all together and revert back to string concatenation like we did in the days before template literals were introduced.&lt;/p&gt;
&lt;pre class="javascript"&gt;const domain = 'app.' + environment + '.my-really-cool-app.com';
&lt;/pre&gt;
&lt;h2 id="terraform-variables-vs-environment-variables"&gt;Terraform Variables vs Environment Variables&lt;/h2&gt;
&lt;p&gt;Using environment variables when writing your config with CDKTF and deploying with Terraform Cloud can be fraught, to say the least.  There's at least one very good reason to use environment variables when using the Auth0 provider: they recommend it &lt;a href="https://registry.terraform.io/providers/auth0/auth0/0.44.0/docs#environment-variables"&gt;in the docs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let's clarify something first.  Because of how CDKTF works, environment variables can be inserted in at least two stages: synthesis and planning.&lt;/p&gt;
&lt;p&gt;If you do anything in your code using &lt;code&gt;process.env&lt;/code&gt; to get at environment variables, this is at best confusing, at worst incorrect. This is how you'd read environment variables &lt;em&gt;at synthesis time&lt;/em&gt;, which is probably not what you actually want.  Doing this would affect what is output to your Terraform JSON when you run CDKTF's synthesis step.  It essentially becomes a hard-coded value from the point of view of Terraform.&lt;/p&gt;
&lt;p&gt;What you probably want to do, and what the Auth0 provider documentation is referring to, is environment variables &lt;em&gt;at planning time&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The environment variables the docs refer to, &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt;, &lt;code&gt;AUTH0_CLIENT_ID&lt;/code&gt;, and &lt;code&gt;AUTH0_CLIENT_SECRET&lt;/code&gt;, are not &lt;em&gt;directly&lt;/em&gt; accessible to your Terraform config.&lt;sup class="footnote-ref" id="fnref-2"&gt;&lt;a href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt; I need to set these values as secrets for one of my hooks.&lt;/p&gt;
&lt;h3 id="the-most-correcttm-way"&gt;The Most Correctâ„¢ Way&lt;/h3&gt;
&lt;p&gt;As I said, you can't &lt;em&gt;directly&lt;/em&gt; access those environment variables for reasons I'll soon explain.  Terraform-literate readers will already know that the Most Correctâ„¢ way to access the values would be &lt;em&gt;indirectly&lt;/em&gt; via the resources that use them.  This is The Terraform Way.&lt;/p&gt;
&lt;p&gt;If this configuration was written in HCL, this would be comically easy.  But we're using CDKTF for reasons I can't begin to explain.&lt;/p&gt;
&lt;p&gt;You should be able to access &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt;, &lt;code&gt;AUTH0_CLIENT_ID&lt;/code&gt;, and &lt;code&gt;AUTH0_CLIENT_SECRET&lt;/code&gt; via &lt;code&gt;Auth0Provider#domainInput&lt;/code&gt;, &lt;code&gt;Client#clientId&lt;/code&gt;, and &lt;code&gt;Client#clientSecret&lt;/code&gt;, respectively.  But my config isn't written in a way that would make this easy.  It would require a ton of refactoring that I don't have the time or patience for at the moment.&lt;/p&gt;
&lt;h3 id="the-quick-n-hacky-way"&gt;The Quick 'N' Hacky Way&lt;/h3&gt;
&lt;p&gt;Since I can't access those particular environment variables directly, and I'm unable to access the values indirectly via the resources that consume them, I chose to add some duplicate variables that I &lt;em&gt;could&lt;/em&gt; access like any other variable.&lt;/p&gt;
&lt;p&gt;The official way to get values into Terraform at planning time via environment variables is to use them in your CDKTF configuration just like any other variable (using the &lt;code&gt;TerraformVariable&lt;/code&gt; class), and set an environment variable in Terraform Cloud with the same name but with a &lt;code&gt;TF_VAR_&lt;/code&gt; prefix.&lt;/p&gt;
&lt;p&gt;That meant that for my use case, I needed both &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt; &lt;em&gt;and&lt;/em&gt; &lt;code&gt;TF_VAR_AUTH0_DOMAIN&lt;/code&gt; set in my Terraform Cloud variables config page,&lt;sup class="footnote-ref" id="fnref-3"&gt;&lt;a href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt; along with the remaining two variables mentioned earlier, using this same pattern.  If I only set &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt;, the Auth0 provider will work, but the &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt; &lt;em&gt;Terraform variable&lt;/em&gt; defaulted to an empty string!  If I set &lt;code&gt;TF_VAR_AUTH0_DOMAIN&lt;/code&gt; but not &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt;, I got the following error during the planning phase.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The argument "domain" is required, but no definition was found.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I chose to set both &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt; and &lt;code&gt;TF_VAR_AUTH0_DOMAIN&lt;/code&gt; as environment variables in Terraform Cloud because that's ever-so-slightly less confusing IMHO than two variables, both named &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt;, one a Terraform variable and the other an environment variable.  I figure someone would be more likely to erroneously delete one of the two copies in the future if both variables shared the same exact name but were different variable types.  As always, notes and documentation are your best friends.&lt;/p&gt;
&lt;hr&gt;
&lt;section class="footnotes"&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;&lt;p&gt;I've seen some bizarre alternative ways of escaping &lt;code&gt;${&lt;/code&gt; suggested on Stack Overflow, but all of my criticism still apply.&lt;a class="footnote" href="#fnref-1"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn-2"&gt;&lt;p&gt;There &lt;em&gt;are&lt;/em&gt; ways you can expose all environment variables as Terraform variables without having to know the variables' keys beforehand, but it's not what The Architects intended.  I've only seen examples of these techniques in HCL.  It might be possible to accomplish in CDKTF, but you'd be fighting your chosen tools so hard that I'd question the whole endeavor.  Just because you &lt;em&gt;can&lt;/em&gt; doesn't mean you &lt;em&gt;should&lt;/em&gt;.&lt;a class="footnote" href="#fnref-2"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn-3"&gt;&lt;p&gt;In case you were wondering, you still need to add the &lt;code&gt;TF_VAR_&lt;/code&gt; prefix yourself in Terraform Cloud. That wasn't immediately clear to me.  I'm guessing it's to support environment variables that don't start with &lt;code&gt;TF_VAR_&lt;/code&gt; since providers (like Auth0 with &lt;code&gt;AUTH0_DOMAIN&lt;/code&gt;, etc.) aren't required to conform to that pattern.  &lt;img alt="Don't forget TF_VAR_" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1678334687-0.png"&gt;&lt;a class="footnote" href="#fnref-3"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
&lt;/div&gt;</description>
      <author>hidden (jaysherby)</author>
      <guid isPermaLink="false">https://jaysherby.com/terraform-cloud-cdktf-auth0/</guid>
      <pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>HP Dev One, low disk space on /boot/efi</title>
      <link>https://jaysherby.com/hp-dev-one-low-disk-space-on-bootefi/</link>
      <description>&lt;div&gt;&lt;p&gt;I always seem to back the wrong horse when it comes to laptops.  Long story short, I was one of the suckers who bought the HP Dev One.  Don't get me wrong, I'm generally very happy with it.  But HP discontinued the line and my daily driver laptop is a technological dead end.&lt;/p&gt;
&lt;p&gt;Recently I started receiving warning messages that my boot partition, &lt;code&gt;/boot/efi&lt;/code&gt; is low on space.  Sure enough, the 512 MB boot partition is 96% full.&lt;/p&gt;
&lt;p&gt;I searched the internet and while there are plenty of people complaining about this issue, there seem to be few fixes.  Many recommend increasing the size of the partition to 1 GB, though they admit it's a complicated process to do so.  The easiest way is a full reinstall of the OS, although you can technically resize the partitions without such a drastic course of action if you're willing to futz around.&lt;/p&gt;
&lt;p&gt;I tried doing a "system refresh" via means built into Pop!_OS. I didn't lose any of my personal data, but I did have to reinstall all my applications. It seemed to fix the issue, although boot partition usage still hovered on the brink at 95%.&lt;/p&gt;
&lt;p&gt;That fix lasted all of a week.  There was another kernel update today causing usage to hit 97%. The warning returned.&lt;/p&gt;
&lt;p&gt;I did some more searching today and found &lt;a href="https://github.com/pop-os/pop/issues/1714"&gt;this GitHub thread&lt;/a&gt;. For posterity, if you're using an HP Dev One laptop like I am, there's a high likelihood that an old, already installed firmware update is hanging around in the boot partition, taking up precious space.&lt;/p&gt;
&lt;p&gt;It's safe to delete &lt;code&gt;/boot/efi/EFI/HP&lt;/code&gt; and &lt;code&gt;/boot/efi/EFI/pop&lt;/code&gt; directories, which hold firmware update files.&lt;/p&gt;
&lt;p&gt;After deleting those directories, my boot partition is now down to a relatively safe 82% usage.&lt;/p&gt;
&lt;/div&gt;</description>
      <author>hidden (jaysherby)</author>
      <guid isPermaLink="false">https://jaysherby.com/hp-dev-one-low-disk-space-on-bootefi/</guid>
      <pubDate>Sun, 12 Mar 2023 20:44:25 +0000</pubDate>
    </item>
    <item>
      <title>Randomizing My MAC Address With NetworkManager</title>
      <link>https://jaysherby.com/randomizing-mac-addresses-with-networkmanager/</link>
      <description>&lt;div&gt;&lt;p&gt;My life is harder for knowing and caring about my own privacy and security.  For example, if you've ever connected to the wifi at a Starbucks using a laptop, you'll have noticed the "captive portal" system they use.  That's the page that pops up before you can actually use the internet.  It asks you for your name, email address, and zip code.&lt;/p&gt;
&lt;p&gt;You may also notice that once you fill out that form, you never have to do it again.  Every time you connect to the Starbucks wifi afterwards, it'll usually still give you a captive portal page, but you'll never have to "log in" again.  This usually holds true &lt;em&gt;even if you visit a different Starbucks with the same computer.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Guess what? Starbucks is tracking you.&lt;sup class="footnote-ref" id="fnref-1"&gt;&lt;a href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; I don't like that, so I lie every time I fill out that form.&lt;sup class="footnote-ref" id="fnref-2"&gt;&lt;a href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;em&gt;Or do I?&lt;/em&gt; ðŸ˜‰&lt;/p&gt;
&lt;p&gt;The way Starbucks remembers your computer is by recording the MAC address of your wifi adapter.&lt;/p&gt;
&lt;p&gt;This is a very old, very well-known privacy risk. Most operating systems have made it relatively easy to spoof your MAC address with a semi-randomly generated one to mitigate this risk. Some even do this by default now.&lt;/p&gt;
&lt;p&gt;Even so, I have particular preferences for how I prefer this feature to work that my system's default settings don't meet.&lt;/p&gt;
&lt;p&gt;I'm using Pop!_OS, which uses NetworkManager.  I'll show you its default setup, how I changed it, and why.&lt;/p&gt;
&lt;p&gt;Here's the default config, located at &lt;code&gt;/etc/NetworkManager/NetworkManager.conf&lt;/code&gt;, that shipped with my machine:&lt;/p&gt;
&lt;pre&gt;[main]
plugins=ifupdown,keyfile

[ifupdown]
managed=false

[device]
wifi.scan-rand-mac-address=no

&lt;/pre&gt;
&lt;p&gt;Shame on you, Pop!_OS!  See &lt;code&gt;wifi.scan-rand-mac-address=no&lt;/code&gt;?  That turns off MAC randomization during access point scanning! That means you're leaking your MAC address before you even connect to wifi. Passive listeners can track you. This isn't even the default behavior &lt;a href="https://blogs.gnome.org/thaller/2016/08/26/mac-address-spoofing-in-networkmanager-1-4-0/"&gt;as of NetworkManager 1.4.0&lt;/a&gt;. This is pretty embarrassing. Even Android randomizes your MAC address when scanning nowadays.&lt;/p&gt;
&lt;p&gt;Here are my changes:&lt;/p&gt;
&lt;pre&gt;[main]
plugins=ifupdown,keyfile

[ifupdown]
managed=false

[device]
wifi.scan-rand-mac-address=yes

[connection]
ethernet.cloned-mac-address=random
wifi.cloned-mac-address=random
&lt;/pre&gt;
&lt;p&gt;I changed &lt;code&gt;wifi.scan-rand-mac-address&lt;/code&gt; to &lt;code&gt;yes&lt;/code&gt;, even though it's the default behavior. Just to be extra sure.&lt;/p&gt;
&lt;p&gt;I also added a setting called &lt;code&gt;cloned-mac-address&lt;/code&gt; to both ethernet&lt;sup class="footnote-ref" id="fnref-3"&gt;&lt;a href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt; and wifi, and set it to &lt;code&gt;random&lt;/code&gt;. This setting has a few other possible values. I'll quote the manual.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Beside explicitly specifying a MAC address, the special values "preserve", "permanent", "random" and "stable" are supported. "preserve" means not to touch the MAC address on activation. "permanent" means to use the permanent hardware address if the device has one (otherwise this is treated as "preserve"). "random" creates a random MAC address on each connect. "stable" creates a hashed MAC address based on connection.stable-id and a machine dependent key.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, &lt;code&gt;permanent&lt;/code&gt; and probably &lt;code&gt;preserve&lt;/code&gt; will leak your physical MAC address when you connect to an access point. &lt;code&gt;stable&lt;/code&gt; won't leak your physical MAC address, but it will result in a given access point seeing the same fake MAC address every time you connect to it.  That doesn't really prevent tracking if every Starbucks access point presents identically.&lt;sup class="footnote-ref" id="fnref-4"&gt;&lt;a href="#fn-4"&gt;4&lt;/a&gt;&lt;/sup&gt; I want &lt;code&gt;random&lt;/code&gt;. It generates a new, random MAC address on every connection.&lt;/p&gt;
&lt;p&gt;There. No more tracking. Now I just have to fill out that stupid captive portal form every time I go to Starbucks with my laptop.&lt;sup class="footnote-ref" id="fnref-5"&gt;&lt;a href="#fn-5"&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id="but-what-if-my-router-yells-at-me"&gt;But what if my router yells at me?&lt;/h2&gt;
&lt;p&gt;This happened to me. My Synology router started sending push notifications to my phone every time I turned on my laptop, asking me if I know this mysterious device that just connected.&lt;/p&gt;
&lt;p&gt;I needed to make an exception to the rules, but just for this one wifi network.  Happily, the option to change this setting is actually in the GUI.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Oh, no! I forgot to censor my home network's SSID!" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1678841041-0.png"&gt;&lt;/p&gt;
&lt;p&gt;You can see here I've set this particular connection to &lt;code&gt;stable&lt;/code&gt;. Works like a charm.&lt;/p&gt;
&lt;p&gt;I'm sure there's a way to do this on the command line, or in a configuration file somewhere, but I haven't needed to figure that out yet.&lt;/p&gt;
&lt;hr&gt;
&lt;section class="footnotes"&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;&lt;p&gt;I have no idea if Starbucks is actively using the data they're collecting, but they &lt;em&gt;are&lt;/em&gt; collecting it. Even if it's just within log files. I mean, they wouldn't ask you a bunch of personal information if they weren't going to use it for &lt;em&gt;something&lt;/em&gt;, right? I'm sure they tell you what they're doing with it in their T&amp;amp;C. But who reads those?&lt;a class="footnote" href="#fnref-1"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn-2"&gt;&lt;p&gt;I've noticed that they'll deny you access if you make up random email domains. Gmail addresses seem to always work, though.&lt;a class="footnote" href="#fnref-2"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn-3"&gt;&lt;p&gt;My laptop doesn't have a built-in ethernet port, so this is probably unnecessary. But it's not hurting anything, and it'll protect me in the one-in-a-million chance I ever plug in a USB-to-ethernet dongle.&lt;a class="footnote" href="#fnref-3"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn-4"&gt;&lt;p&gt;And almost every Starbucks access point does present identically. This is why your phone or laptop will automatically connect to Starbucks wifi even if you've never been to that particular location before.&lt;a class="footnote" href="#fnref-4"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn-5"&gt;&lt;p&gt;Yep.  I'm apparently willing to pay that price because I care that much about my privacy.  Do you think I like living this way?  I guess my Walter Mitty daydreams include living in the world of &lt;em&gt;Hackers (1995)&lt;/em&gt;, and running Silk Road from coffee shops but &lt;em&gt;not&lt;/em&gt; getting caught like Ulbricht did.&lt;a class="footnote" href="#fnref-5"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
&lt;/div&gt;</description>
      <author>hidden (jaysherby)</author>
      <guid isPermaLink="false">https://jaysherby.com/randomizing-mac-addresses-with-networkmanager/</guid>
      <pubDate>Tue, 14 Mar 2023 23:31:40 +0000</pubDate>
    </item>
    <item>
      <title>Tips For Becoming A Pod Person</title>
      <link>https://jaysherby.com/tips-for-becoming-a-pod-person/</link>
      <description>&lt;div&gt;&lt;p&gt;&lt;img alt="Original art, with apologies to Donald Sutherland" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1679176611-0.png"&gt;&lt;/p&gt;
&lt;p&gt;I made the leap from Docker to Podman.  Well... only on my personal laptop. Podman isn't a completely hassle-free, drop-in replacement for Docker.  It's damn close!  Close enough that I'm willing to use it at home, but it's still finicky and different enough that I'd spend too much time futzing at work trying to use it while keeping everything Docker-compatible for my colleagues.&lt;/p&gt;
&lt;p&gt;Here are some tips if, like me, you're coming from Docker and you just want to get productive.&lt;/p&gt;
&lt;h2 id="i-need-docker-compose"&gt;I need Docker Compose&lt;/h2&gt;
&lt;p&gt;A large part of Docker's value to me comes from Docker Compose. If switching to Podman meant losing Docker Compose, I wouldn't have switched.&lt;/p&gt;
&lt;p&gt;Thankfully, Pop!_OS (and probably any other platforms that include Podman in their repos) has a package called &lt;code&gt;podman-docker&lt;/code&gt; that satisfies packages that depend on Docker. Just make sure you install &lt;code&gt;podman-docker&lt;/code&gt; before or at the same time as &lt;code&gt;docker-compose&lt;/code&gt; so APT doesn't try to install Docker to satisfy Docker Compose's dependencies.&lt;/p&gt;
&lt;p&gt;If you're feeling adventurous, &lt;a href="https://github.com/containers/podman-compose"&gt;Podman Compose&lt;/a&gt; is a thing. But it's not available via my OS's default repositories and Docker Compose is.&lt;/p&gt;
&lt;h2 id="i-need-docker-hub"&gt;I need Docker Hub&lt;/h2&gt;
&lt;p&gt;I also wouldn't use Podman if it meant I lost Docker Hub.&lt;/p&gt;
&lt;p&gt;The easiest way to get access to Docker Hub with Podman is to write the following file to &lt;code&gt;$HOME/.config/containers/registries.conf&lt;/code&gt;:&lt;sup class="footnote-ref" id="fnref-1"&gt;&lt;a href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;pre&gt;[registries.search]
registries = ['docker.io']
&lt;/pre&gt;
&lt;h2 id="potentially-insufficient-uids-or-gids-available-in-user-namespace"&gt;Potentially insufficient UIDs or GIDs available in user namespace&lt;/h2&gt;
&lt;p&gt;I had just installed Podman and I wanted use the NodeJS image from Docker Hub.&lt;/p&gt;
&lt;pre&gt;$ podman run -it --rm node
Resolving "node" using unqualified-search registries (/home/jsherby/.config/containers/registries.conf)
Trying to pull docker.io/library/node:latest...
Getting image source signatures
Copying blob ca3bce705f6c done  
Copying blob 167c7feebee8 done  
Copying blob e9cdcd4942eb done  
Copying blob 32fb02163b6b done  
Copying blob d6dfff1f6f3d done  
Copying blob 4f4cf292bc62 done  
Copying blob 8347f8b4b86b done  
Copying blob c5f20f1b0856 done  
Copying blob d220dfa3e187 done  
Error: writing blob: adding layer with blob "sha256:32fb02163b6bb519a30f909008e852354dae10bdfd6b34190dbdfe8f15403ea0": Error processing tar file(exit status 1): potentially insufficient UIDs or GIDs available in user namespace (requested 0:42 for /etc/gshadow): Check /etc/subuid and /etc/subgid: lchown /etc/gshadow: invalid argument

&lt;/pre&gt;
&lt;p&gt;This seems to be a common issue.&lt;/p&gt;
&lt;p&gt;First, make sure the &lt;code&gt;fuse-overlayfs&lt;/code&gt; package is installed.&lt;/p&gt;
&lt;p&gt;If you look around the internet, you're going to find advice telling you to add the following file at &lt;code&gt;$HOME/.config/containers/storage.conf&lt;/code&gt;:&lt;sup class="footnote-ref" id="fnref-2"&gt;&lt;a href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;pre&gt;[storage]
driver = "overlay"

[storage.options.overlay]
ignore_chown_errors = "true"
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;BUT BE WARNED!&lt;/strong&gt; This change is meaningful and makes Podman behave differently than you probably expect. I'll quote the manual directly.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ignore_chown_errors can be set to allow a non privileged user running with a single UID within a user namespace to run containers. The user can pull and use any image even those with multiple uids. Note multiple UIDs will be squashed down to the default uid in the container. These images will have no separation between the users in the container.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Although this setup will make Podman stop complaining, there's a good chance this will bite you in the ass later on, especially if you're trying to stay compatible with Docker.&lt;/p&gt;
&lt;p&gt;Instead, I added my user to &lt;code&gt;/etc/subuid&lt;/code&gt; and &lt;code&gt;/etc/subgid&lt;/code&gt;.  Here's what both files look like on my machine:&lt;sup class="footnote-ref" id="fnref-3"&gt;&lt;a href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;pre&gt;jsherby:100000:65536
&lt;/pre&gt;
&lt;p&gt;Then I ran &lt;code&gt;podman system migrate&lt;/code&gt; and I was good to go.&lt;/p&gt;
&lt;hr&gt;
&lt;section class="footnotes"&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;&lt;p&gt;&lt;code&gt;/etc/containers/registries.conf&lt;/code&gt; is the equivalent system-wide config file.&lt;a class="footnote" href="#fnref-1"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn-2"&gt;&lt;p&gt;&lt;code&gt;/etc/containers/storage.conf&lt;/code&gt; is the equivalent system-wide config file.&lt;a class="footnote" href="#fnref-2"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn-3"&gt;&lt;p&gt;When supporting namespaces for multiple users, the middle value needs to be offset so the namespaces don't overlap. Check the man pages that come with your local &lt;code&gt;shadow&lt;/code&gt; package for details.&lt;a class="footnote" href="#fnref-3"&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
&lt;/div&gt;</description>
      <author>hidden (jaysherby)</author>
      <guid isPermaLink="false">https://jaysherby.com/tips-for-becoming-a-pod-person/</guid>
      <pubDate>Thu, 16 Mar 2023 00:36:53 +0000</pubDate>
    </item>
    <item>
      <title>Back That Blog Up</title>
      <link>https://jaysherby.com/back-that-blog-up/</link>
      <description>&lt;div&gt;&lt;p&gt;&lt;img alt="The Sherbmeister. Makin' copies." src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1679543245-0.png"&gt;&lt;/p&gt;
&lt;p&gt;There was a post on Hacker News about a week ago titled &lt;a href="https://news.ycombinator.com/item?id=35164819"&gt;"Ask HN: What has your personal website/blog done for you?"&lt;/a&gt;. As someone who has tried to blog for years but only recently started doing it in earnest, a lot of comments rang true to me.&lt;/p&gt;
&lt;p&gt;I, too, have bounced off of many static site generators. While I strongly agree with the ethos behind static site generators, I find the barrier to writing to be too high. When I'm in the mood to write, I need to be able to load up a web page with a text box and just start writing.&lt;/p&gt;
&lt;p&gt;Bear Blog, the service I'm currently using to host this site, provides exactly what I need. Kudos to &lt;a href="https://herman.bearblog.dev/"&gt;Herman Martinus&lt;/a&gt; for developing and maintaining this fantastic service.&lt;/p&gt;
&lt;p&gt;There was something else in that Hacker News thread that made me a little nervous, though. &lt;a href="https://news.ycombinator.com/item?id=35201556"&gt;A particular comment&lt;/a&gt; mentioned keeping copies of their blog posts, which came in handy when their platform of choice shut down. Many others echoed this sentiment of keeping backups of your work, just in case.&lt;/p&gt;
&lt;p&gt;Herman is doing a fantastic job, but he's only one person, and shit happens sometimes. I decided build a little safety net by using GitHub Actions to automatically back up my blog.&lt;/p&gt;
&lt;h2 id="a-shell-script"&gt;A shell script&lt;/h2&gt;
&lt;details&gt;
&lt;summary&gt;View the complete shell script&lt;/summary&gt;
&lt;h3 id="github-workflows-backup-sh"&gt;&lt;code&gt;.github/workflows/backup.sh&lt;/code&gt;&lt;/h3&gt;
&lt;pre class="bash"&gt;#! /bin/sh

set -e
set -u

# Delete all directories that are not hidden to avoid keeping deleted files.
find . -maxdepth 1 -type d -not -name '.*' -exec rm -r "{}" \;

# Download website and images, ignoring /hit and /upvote paths.
wget --wait=2 \
     --mirror \
     --page-requisites \
     --no-parent \
     --convert-links \
     --adjust-extension \
     --span-hosts \
     --domains="jaysherby.com,digitaloceanspaces.com" \
     --exclude-directories="hit,upvote" \
     -e robots=off \
     https://jaysherby.com

# Delete CSRF tokens since they'll change every page load.
# Delete last build date tag since it will change often.
find . -type f -name "*.html*" \
       -exec sed -i '/&amp;lt;input.*name="csrfmiddlewaretoken".*&amp;gt;/d' {} \; \
       -exec sed -i '/&amp;lt;lastBuildDate&amp;gt;.*&amp;lt;\/lastBuildDate&amp;gt;/d' {} \;

# Detect any added, changed, or deleted files
if [ -n "$(git ls-files --modified --deleted --others)" ]; then
  git add -A
  git commit -m "Backup $(date)"
  git push origin main
fi
&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;Let me start with Wget. It's doing the heavy lifting here to basically crawl my site and download everything.&lt;/p&gt;
&lt;pre class="bash"&gt;wget --wait=2 \
     --mirror \
     --page-requisites \
     --no-parent \
     --convert-links \
     --adjust-extension \
     --span-hosts \
     --domains="jaysherby.com,digitaloceanspaces.com" \
     --exclude-directories="hit,upvote" \
     -e robots=off \
     https://jaysherby.com
&lt;/pre&gt;
&lt;p&gt;Most of these options are copy-pasted from an article I found called &lt;a href="https://simpleit.rocks/linux/how-to-download-a-website-with-wget-the-right-way/"&gt;"How To Download A Website With Wget The Right Way"&lt;/a&gt;. I prefer having the options spelled out long-hand in scripts like this over single character arguments. It's easier to understand.&lt;/p&gt;
&lt;p&gt;I made a few changes from the example on the site I linked to above.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I removed the &lt;code&gt;--user-agent&lt;/code&gt; argument. Wget's default is fine.&lt;/li&gt;
&lt;li&gt;I removed the &lt;code&gt;--no-clobber&lt;/code&gt; argument because it's not pertinent in my case for reasons that will become clear in a moment.&lt;/li&gt;
&lt;li&gt;I removed the &lt;code&gt;--limit-rate=20K&lt;/code&gt; argument because although I understand the purpose of setting &lt;code&gt;--wait=2&lt;/code&gt; to avoid overwhelming the server with a ton of requests all at once, it seems to me like limiting the transfer speed would end up wasting precious time that could be spent serving other clients. It really doesn't matter for the amount of traffic I get anyway.&lt;/li&gt;
&lt;li&gt;I added &lt;code&gt;--span-hosts&lt;/code&gt; and &lt;code&gt;--domains=&amp;amp;quot;jaysherby.com,digitaloceanspaces.com&amp;amp;quot;&lt;/code&gt; to ensure images are downloaded. Bear Blog is currently hosted on Digital Ocean and images are stored in their Spaces product, which is more or less a clone of AWS S3. This feature is currently configured such that image URLs live in a subdomain of &lt;code&gt;digitaloceanspaces.com&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I added &lt;code&gt;--exclude-directories=&amp;amp;quot;hit,upvote&amp;amp;quot;&lt;/code&gt;. Wget was downloading files from &lt;code&gt;/hit&lt;/code&gt; which is how Bear Blog powers its analytics service. It's currently implemented by setting URLs in that path as a border image applied to the page body on hover. Clever! But it currently only returns a response of &lt;a href="https://github.com/HermanMartinus/bearblog/blob/89cff8645af2e7b21d382dc59ed7eacfb7b971d3/blogs/views/analytics.py#L69"&gt;"Logged"&lt;/a&gt;, which is useless for my backups and would present as noise in my analytics. The &lt;code&gt;/upvote&lt;/code&gt; path is how posts are "toasted". Wget should never follow these by default since they are form actions, but better safe than sorry.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="bash"&gt;# Delete CSRF tokens since they'll change every page load.
# Delete last build date tag since it will change often.
find . -type f -name "*.html*" \
       -exec sed -i '/&amp;lt;input.*name="csrfmiddlewaretoken".*&amp;gt;/d' {} \; \
       -exec sed -i '/&amp;lt;lastBuildDate&amp;gt;.*&amp;lt;\/lastBuildDate&amp;gt;/d' {} \;
&lt;/pre&gt;
&lt;p&gt;This command looks through the HTML files and removes two patterns from them.&lt;/p&gt;
&lt;p&gt;The first is a hidden input within the "toast" forms that contains a CSRF token. I'm removing this because, as the comment says, the value will be different on every page load. That will make for a lot of unnecessary noise in my backups.&lt;/p&gt;
&lt;p&gt;The second is the last build date tag that is found within my blog's RSS file. This is updated on a regular basis whether any content has changed or not. Again, this would make for a lot of noise in my backups.&lt;/p&gt;
&lt;p&gt;Notice in the second sed command that the slash in the HTML tag is escaped! I originally overlooked this and it bit me. ðŸ¤¦&lt;/p&gt;
&lt;p&gt;Quick shout out to &lt;a href="https://sed.js.org/"&gt;this website&lt;/a&gt; that is like &lt;a href="https://regex101.com/"&gt;Regex 101&lt;/a&gt; for sed. It saved me a lot of time testing out my sed commands.&lt;/p&gt;
&lt;pre class="bash"&gt;# Detect any added, changed, or deleted files
if [ -n "$(git ls-files --modified --deleted --others)" ]; then
  git add -A
  git commit -m "Backup $(date)"
  git push origin main
fi
&lt;/pre&gt;
&lt;p&gt;This does what it says on the tin.  It uses the &lt;code&gt;git ls-files&lt;/code&gt; command to determine if any files have changed. If so, it makes a commit with the current timestamp in the commit message and pushes it up.&lt;/p&gt;
&lt;p&gt;Let's skip back to the beginning of the script.&lt;/p&gt;
&lt;pre class="bash"&gt;# Delete all directories that are not hidden to avoid keeping deleted files.
find . -maxdepth 1 -type d -not -name '.*' -exec rm -r "{}" \;
&lt;/pre&gt;
&lt;p&gt;If the script has run at least once before, the git repository will have two directories at its root: &lt;code&gt;jaysherby.com&lt;/code&gt; and &lt;code&gt;bear-images.sfo2.cdn.digitaloceanspaces.com&lt;/code&gt;. This command is a little idiosyncratic for a shell script, but it mimics what I would do at the command line. It finds and recursively deletes all top-level, non-hidden directories.&lt;/p&gt;
&lt;p&gt;This is to facilitate the removal of potentially deleted pages and files. For the purposes of my backups, I want the git history to reflect file deletion since I can always recover deleted content.&lt;/p&gt;
&lt;p&gt;Unfortunately, Wget doesn't have anything built into it like Rsync's various &lt;code&gt;--delete&lt;/code&gt; arguments, which will make sure your source and destination match exactly after synchronization by deleting files from the destination that no longer exist at the source.&lt;/p&gt;
&lt;p&gt;I find this particularly unfortunate because it means having to download my blog's images on every backup attempt despite Wget's automatic &lt;code&gt;If-Modified-Since&lt;/code&gt; header support and Digital Ocean Spaces' &lt;code&gt;304 Not Modified&lt;/code&gt; support. Bear Blog itself doesn't appear to support &lt;code&gt;If-Modified-Since&lt;/code&gt; request headers at this time. Although that doesn't really matter since I can't leverage it anyway.&lt;/p&gt;
&lt;h2 id="a-github-actions-workflow"&gt;A GitHub Actions workflow&lt;/h2&gt;
&lt;details&gt;
&lt;summary&gt;View the complete YAML file&lt;/summary&gt;
&lt;h3 id="github-workflows-backup-yml"&gt;&lt;code&gt;.github/workflows/backup.yml&lt;/code&gt;&lt;/h3&gt;
&lt;pre class="yml"&gt;name: Back Up Website

on:
  schedule:
    - cron: "0 17 * * *"

  workflow_dispatch:

jobs:
  back-up:
    runs-on: ubuntu-latest
    steps:
      - uses: "actions/checkout@v3"

      - name: Install required packages
        run: |
          sudo apt-get update
          sudo apt-get install -y findutils git sed wget

      - name: Configure identity
        run: |
          git config --global user.email "10983817+hexpunk@users.noreply.github.com"
          git config --global user.name "hexpunk"

      - name: Run backup script
        run: sh $GITHUB_WORKSPACE/.github/workflows/backup.sh
&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;The GitHub Actions workflow file was thankfully straightforward to write.&lt;/p&gt;
&lt;pre class="yaml"&gt;on:
  schedule:
    - cron: "0 17 * * *"

  workflow_dispatch:
&lt;/pre&gt;
&lt;p&gt;Run the script daily at noon Central Standard Time, my local time zone, so if it ever fails, I get emailed about it at a reasonable time. GitHub Actions are set to Coordinated Universal Time, hence the offset. I used &lt;a href="https://crontab.guru/"&gt;this website&lt;/a&gt; to refresh my memory of cron expression syntax.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;workflow_dispatch&lt;/code&gt; key is there so I can run the job manually via the web interface if I need to.&lt;/p&gt;
&lt;pre class="yaml"&gt;jobs:
  back-up:
    runs-on: ubuntu-latest
    steps:
      - uses: "actions/checkout@v3"

      - name: Install required packages
        run: |
          sudo apt-get update
          sudo apt-get install -y findutils git sed wget
&lt;/pre&gt;
&lt;p&gt;The first step checks out the git repository. The second step installs all required software to run the script. All of these tools are currently installed by default in the &lt;code&gt;ubuntu-latest&lt;/code&gt; job runner. Better safe than sorry, though.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://docs.github.com/en/actions/using-github-hosted-runners/customizing-github-hosted-runners"&gt;Remember to use &lt;code&gt;sudo&lt;/code&gt;&lt;/a&gt; to install software in GitHub's &lt;code&gt;ubuntu-latest&lt;/code&gt; job runner, unlike the usual situation for Docker containers. This one bit me.&lt;/p&gt;
&lt;pre class="yaml"&gt;- name: Configure identity
  run: |
    git config --global user.email "10983817+hexpunk@users.noreply.github.com"
    git config --global user.name "hexpunk"
&lt;/pre&gt;
&lt;p&gt;I was surprised to find out the job runner didn't have any git identity set up by default. I added my own username and GitHub's email alias for my account. If you're not using your email alias on GitHub, &lt;a href="https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-personal-account-on-github/managing-email-preferences/setting-your-commit-email-address"&gt;you really should be&lt;/a&gt;.&lt;/p&gt;
&lt;pre class="yaml"&gt;- name: Run backup script
  run: sh $GITHUB_WORKSPACE/.github/workflows/backup.sh
&lt;/pre&gt;
&lt;p&gt;Finally, run the script I wrote.&lt;/p&gt;
&lt;h2 id="setting-permissions"&gt;Setting permissions&lt;/h2&gt;
&lt;p&gt;One last consideration before this setup is ready to roll. Because the shell script is checking files into git, I had to set up the repository's Actions settings accordingly.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Give Actions read and write permissions." src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1679587165-0.png"&gt;&lt;/p&gt;
&lt;p&gt;The repository I set up for this is public. GitHub sets a monthly limit to the amount of time Actions can run per month on private repositories before you're either cut off or you have to pay. I don't want randos taking advantage of this to run malicious actions, so I set this setting to disallow unapproved collaborators from triggering Actions.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Strangers shouldn't be able to run Actions on this repository." src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1679587578-0.png"&gt;&lt;/p&gt;
&lt;p&gt;Finally, I set the repository so only actions authored by me and GitHub can be run. I need to allow GitHub's official actions since I'm using their "checkout" action in my workflow.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Only allow my actions and GitHub's actions." src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/jaysherby-1679587709-0.png"&gt;&lt;/p&gt;
&lt;p&gt;This setting is a little redundant since I've already disallowed unapproved collaborators, but better safe than sorry.&lt;/p&gt;
&lt;p&gt;That's it. Works like a charm. Every day at noon, it automatically backs up my blog for free.&lt;/p&gt;
&lt;p&gt;This approach should be adaptable for backing up almost any kind of website.&lt;/p&gt;
&lt;h2 id="how-might-this-fail"&gt;How might this fail?&lt;/h2&gt;
&lt;p&gt;Whenever I have to make choices that involve trade-offs, I like to document how my decisions might betray me down the line.&lt;/p&gt;
&lt;p&gt;First and foremost, I'm completely at Herman's mercy here. He may choose to change how Bear Blog works in ways that will make my script fail. If he changes how analytics, upvotes, or image storage works, it may break my backups in ways I won't immediately notice.&lt;/p&gt;
&lt;p&gt;Second, I'm also at the mercy of Microsoft since I'm relying on GitHub. In the unlikely event that GitHub completely disappears one day, my backups are gone. Microsoft could also choose to fundamentally change how their Actions product works, or what versions of software packages are available on the platform.&lt;/p&gt;
&lt;p&gt;Microsoft could also suddenly decide my use of GitHub as a backup storage service runs afoul of their T&amp;amp;C. Seems unlikely. I doubt I'm costing them an entire cent. But it's technically possible.&lt;/p&gt;
&lt;p&gt;I find these risks acceptable for my use case.&lt;/p&gt;
&lt;/div&gt;</description>
      <author>hidden (jaysherby)</author>
      <guid isPermaLink="false">https://jaysherby.com/back-that-blog-up/</guid>
      <pubDate>Wed, 22 Mar 2023 17:17:00 +0000</pubDate>
    </item>
  </channel>
</rss>
